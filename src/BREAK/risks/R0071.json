{
  "R0071": {
    "title": "生成式AI风险",
    "definition": "AIGC（Artificial Intelligence Generated Content）生成式人工智能带来的相关风险隐患",
    "description": "AI生成内容风险大致分成几方面：将敏感的信息生成到内容当中造成敏感信息泄露风险；生成的内容含有违法、违规、违法伦理道德等方面风险；批量、廉价且劣质的AI生成内容带来的平台内容质量下降风险",
    "complexity": "初级",
    "influence": "AI生成内容风险可能会给平台带来合规风险，以及客诉量的增加",
    "avoidances": [
      "A0035",
      "A0035-001",
      "A0006",
      "A0045",
      "A0064",
      "A0065"
    ],
    "references": [
      {
        "title": "AIGC - 百度百科",
        "link": "https://baike.baidu.com/item/AIGC/59988381?fr=ge_ala"
      },
      {
        "title": "AIGC带来的安全隐患有哪些？",
        "link": "https://baijiahao.baidu.com/s?id=1778727153917782040&wfr=spider&for=pc"
      }
    ],
    "updated": "2024-01-15"
  },
  "R0071-001": {
    "title": "AIGC隐私泄露",
    "definition": "AIGC将大模型训练出来的敏感信息泄露到内容当中",
    "description": "敏感信息泄露可能发生在多个方面：①训练数据中的信息泄露： 如果在训练大语言模型时使用了包含敏感信息的文本数据，模型可能会在生成内容时基于这些数据生成类似的敏感信息。②模型记忆性： 大语言模型有时候可能表现出记忆性，即在生成的文本中包含先前输入的信息。如果用户在对话中提供了敏感信息，模型可能会在后续的生成中包含这些信息。③上下文敏感性： 模型在生成文本时可能基于先前的上下文，这可能包括用户提供的敏感信息。即使用户不再明确提及敏感信息，模型也可能在后续的生成中暗示或包含相关信息。",
    "complexity": "中级",
    "influence": "AIGC敏感信息泄露可能会给平台带来合规风险",
    "avoidances": [
      "A0035",
      "A0035-001",
      "A0045"
    ],
    "references": [
      {
        "title": "企业使用AIGC时需要考虑的数据风险有哪些？",
        "link": "https://www.sohu.com/a/713192470_121394207"
      }
    ],
    "updated": "2024-01-15"
  },
  "R0071-002": {
    "title": "AIGC合规风险",
    "definition": "AI生成的内容可能会包含违法、违规、违法伦理道德等方面风险",
    "description": "大语言模型生成内容合规风险主要包括误导性信息、歧视性内容、侵犯隐私、恶意滥用、知识产权问题、合规性问题以及缺乏透明性。这些风险可能导致虚假信息传播、歧视性言论、隐私侵犯、恶意滥用和法规合规性问题。",
    "complexity": "初级",
    "influence": "AI生成内容合规风险可能会给平台带来合规风险，以及客诉量的增加",
    "avoidances": [
      "A0006",
      "A0035-001"
    ],
    "references": [
      {
        "title": "AIGC浪潮下的法律合规风险与防范",
        "link": "https://www.hnjzlaw.net/news/3/1451.html"
      }
    ],
    "updated": "2024-01-15"
  },
  "R0071-003": {
    "title": "AI生成劣质内容",
    "definition": "批量、廉价且劣质的大语言模型生成内容可能带来平台内容质量下降的多种风险",
    "description": "首先，由于这些模型缺乏有效的内容筛选机制，可能导致大量垃圾信息、虚假新闻和低质量评论的涌现，从而降低平台整体内容质量。其次，这些生成的内容可能涉及侵犯隐私、恶意攻击和不当言论，加剧了社交平台上的虚假信息传播和社会紧张氛围。此外，大规模使用语言模型生成内容也可能助长机器人化行为，使得真实用户难以辨别虚假账号和人工生成的内容，进而损害社交平台的信誉和用户体验。",
    "complexity": "中级",
    "influence": "导致平台内容质量下降，影响原创且精致内容博主的积极性",
    "avoidances": [
      "A0043",
      "A0006-008",
      "A0029-001",
      "A0048",
      "A0020"
    ],
    "references": [],
    "updated": "2024-01-15"
  },
  "R0071-004": {
    "title": "AI幻觉风险",
    "definition": "大语言模型生成看似合理但实际上不正确或虚构的信息，即\"幻觉\"（Hallucination），可能误导用户决策。",
    "description": "AI幻觉是指大语言模型在生成内容时，产生与事实不符、逻辑不通或完全虚构的信息，但这些信息在表述上看起来非常自信和合理。主要风险场景包括：①虚假事实生成：模型编造不存在的事件、人物、数据或引用来源。②错误专业建议：在医疗、法律、金融等专业领域生成错误的建议，可能导致严重后果。③虚假引用：生成看似真实但实际不存在的学术论文、法律条文、新闻报道等引用。④逻辑推理错误：在复杂推理任务中产生看似合理但实际错误的推理链条。",
    "complexity": "中级",
    "influence": "用户被误导做出错误决策、专业领域的错误建议可能造成严重后果、平台可信度下降",
    "avoidances": [
      "A0065",
      "A0064",
      "A0006",
      "A0048"
    ],
    "references": [
      {
        "title": "大语言模型幻觉问题综述",
        "link": "https://arxiv.org/abs/2311.05232"
      }
    ],
    "updated": "2026-02-27"
  },
  "R0071-005": {
    "title": "AI模型投毒风险",
    "definition": "攻击者通过污染训练数据或模型参数，使AI模型产生预设的错误行为或后门的风险。",
    "description": "AI模型投毒是指攻击者在模型训练阶段或微调阶段，通过注入恶意数据或修改模型参数，使模型在特定触发条件下产生攻击者预期的错误输出。主要攻击方式包括：①数据投毒：在训练数据中注入精心构造的恶意样本，使模型学习到错误的模式。②后门攻击：在模型中植入后门，当输入包含特定触发器时，模型输出被攻击者控制的结果。③模型篡改：在模型分发过程中篡改模型权重，植入恶意行为。④联邦学习投毒：在联邦学习场景中，恶意参与方提交有毒的模型更新。",
    "complexity": "高级",
    "influence": "AI系统决策被操纵、安全检测被绕过、模型可信度丧失",
    "avoidances": [
      "A0065",
      "A0070",
      "A0052",
      "A0014"
    ],
    "references": [
      {
        "title": "AI模型安全与投毒攻击综述",
        "link": "https://arxiv.org/abs/2302.10149"
      }
    ],
    "updated": "2026-02-27"
  }
}