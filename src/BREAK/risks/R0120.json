{
  "R0120": {
    "title": "AI语音克隆欺诈",
    "definition": "利用AI语音克隆技术伪造他人声音，实施电话诈骗、绕过声纹认证或制造虚假音频证据的风险。",
    "description": "AI语音克隆欺诈是指攻击者利用深度学习语音合成技术，基于少量目标人物的语音样本（甚至仅需几秒钟的录音），即可生成与目标人物高度相似的合成语音。主要风险场景包括：①电话诈骗：冒充亲友、领导或客服人员的声音进行电话诈骗，骗取转账或敏感信息。②声纹认证绕过：利用克隆语音绕过银行、支付平台等的声纹认证系统。③虚假音频证据：制作虚假的通话录音或语音消息，用于敲诈勒索或法律纠纷。④社交工程增强：结合AI语音克隆和深度伪造视频，实施更具欺骗性的社交工程攻击。随着零样本语音克隆技术的成熟，攻击者甚至可以从社交媒体上公开的语音内容中提取足够的样本。",
    "complexity": "高级",
    "influence": "导致电话诈骗成功率大幅提升、声纹认证体系失效、用户财产损失和信任危机",
    "avoidances": [
      "A0066",
      "A0023",
      "A0023-001",
      "A0073",
      "A0007",
      "A0027"
    ],
    "references": [
      {
        "title": "AI语音克隆诈骗案例 - FBI",
        "link": "https://www.ic3.gov/"
      },
      {
        "title": "语音深度伪造检测技术综述",
        "link": "https://arxiv.org/abs/2308.14970"
      }
    ],
    "updated": "2026-02-27"
  }
}