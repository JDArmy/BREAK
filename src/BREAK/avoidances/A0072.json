{
  "A0072": {
    "title": "算法审计机制",
    "category": "AC03",
    "definition": "算法审计机制是指对算法系统进行系统性的检查和评估，以确保算法的公平性、透明性、可解释性和合规性，防止算法歧视、偏见和滥用。",
    "description": "算法审计机制的主要内容包括：①公平性评估：检测算法在不同群体（如性别、年龄、地域等）之间的决策差异，识别潜在的歧视和偏见问题。②透明性审查：评估算法决策过程的透明度，确保用户能够理解影响其权益的算法逻辑。③可解释性分析：利用SHAP、LIME等可解释AI技术，分析算法决策的关键因素和推理路径。④数据审计：审查训练数据的质量、代表性和偏见，确保数据来源合法合规。⑤影响评估：评估算法对用户权益、市场竞争、社会公平等方面的潜在影响。⑥合规检查：对照《互联网信息服务算法推荐管理规定》等法规要求，检查算法系统的合规性。⑦定期复审：建立算法的定期审计制度，跟踪算法性能和公平性指标的变化趋势。⑧第三方审计：引入独立的第三方机构进行算法审计，提高审计的客观性和公信力。",
    "limitation": "算法审计机制的局限性包括：①复杂的深度学习模型本身具有黑盒特性，完全理解其决策逻辑存在技术困难。②公平性的定义在不同场景和文化背景下可能存在差异，难以制定统一标准。③算法审计需要专业的技术能力和领域知识，合格的审计人员和机构相对稀缺。④审计结果可能受到审计方法和评估指标选择的影响。⑤动态更新的算法模型需要持续审计，一次性审计难以保证长期合规。",
    "references": [
      {
        "title": "互联网信息服务算法推荐管理规定",
        "link": "https://www.cac.gov.cn/2022-01/04/c_1642894606364259.htm"
      },
      {
        "title": "算法审计框架 - IEEE",
        "link": "https://standards.ieee.org/industry-connections/ec/autonomous-systems/"
      }
    ],
    "updated": "2026-02-27"
  }
}